{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "  \"Red Bull drops hint on F1 engine.\",\n",
    "  \"Honda exits F1, leaving F1 partner Red Bull.\",\n",
    "  \"Hamilton eyes record eighth F1 title.\",\n",
    "  \"Aston Martin announces sponsor.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['announces' 'aston' 'bull' 'drops' 'eighth' 'engine' 'exits' 'eyes' 'f1'\n",
      " 'hamilton' 'hint' 'honda' 'leaving' 'martin' 'on' 'partner' 'record'\n",
      " 'red' 'sponsor' 'title']\n",
      "{'red': 17, 'bull': 2, 'drops': 3, 'hint': 10, 'on': 14, 'f1': 8, 'engine': 5, 'honda': 11, 'exits': 6, 'leaving': 12, 'partner': 15, 'hamilton': 9, 'eyes': 7, 'record': 16, 'eighth': 4, 'title': 19, 'aston': 1, 'martin': 13, 'announces': 0, 'sponsor': 18}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 8)\t2\n",
      "  (1, 11)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 15)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 19)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 18)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow) #(doc, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Tokenizer callback using spacy\n",
    "def spacy_tokenizer(doc):\n",
    "    return [t.text for t in nlp(doc) if not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True)\n",
    "bow = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aston' 'Bull' 'F1' 'Hamilton' 'Honda' 'Martin' 'Red' 'announces' 'drops'\n",
      " 'eighth' 'engine' 'exits' 'eyes' 'hint' 'leaving' 'on' 'partner' 'record'\n",
      " 'sponsor' 'title']\n",
      "{'Red': 6, 'Bull': 1, 'drops': 8, 'hint': 13, 'on': 15, 'F1': 2, 'engine': 10, 'Honda': 4, 'exits': 11, 'leaving': 14, 'partner': 16, 'Hamilton': 3, 'eyes': 12, 'record': 17, 'eighth': 9, 'title': 19, 'Aston': 0, 'Martin': 5, 'announces': 7, 'sponsor': 18}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dense representation\n",
      "[[0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0]\n",
      " [0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1]\n",
      " [1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "Indexing and slicing\n",
      "  (0, 6)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 10)\t1\n",
      "\n",
      "  (0, 6)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 10)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 16)\t1\n"
     ]
    }
   ],
   "source": [
    "print(\"A dense representation\")\n",
    "print(bow.toarray())\n",
    "print()\n",
    "print(\"Indexing and slicing\")\n",
    "print(bow[0])\n",
    "print()\n",
    "print(bow[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Red Bull drops hint on F1 engine.', 'Honda exits F1, leaving F1 partner Red Bull.', 'Hamilton eyes record eighth F1 title.', 'Aston Martin announces sponsor.']\n",
      "Doc 1 vs Doc 2: 0.4285714285714286\n",
      "Doc 1 vs Doc 3: 0.15430334996209194\n",
      "Doc 1 vs Doc 4: 0.0\n"
     ]
    }
   ],
   "source": [
    "doc1_vs_doc2 = 1 - spatial.distance.cosine(bow[0].toarray(), bow[1].toarray())\n",
    "doc1_vs_doc3 = 1 - spatial.distance.cosine(bow[0].toarray(), bow[2].toarray())\n",
    "doc1_vs_doc4 = 1 - spatial.distance.cosine(bow[0].toarray(), bow[3].toarray())\n",
    "print(corpus)\n",
    "print(f\"Doc 1 vs Doc 2: {doc1_vs_doc2}\")\n",
    "print(f\"Doc 1 vs Doc 3: {doc1_vs_doc3}\")\n",
    "print(f\"Doc 1 vs Doc 4: {doc1_vs_doc4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.42857143 0.15430335 0.        ]\n",
      " [0.42857143 1.         0.15430335 0.        ]\n",
      " [0.15430335 0.15430335 1.         0.        ]\n",
      " [0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aston' 'Aston Martin' 'Bull' 'Bull drops' 'F1' 'F1 engine' 'F1 leaving'\n",
      " 'F1 partner' 'F1 title' 'Hamilton' 'Hamilton eyes' 'Honda' 'Honda exits'\n",
      " 'Martin' 'Martin announces' 'Red' 'Red Bull' 'announces'\n",
      " 'announces sponsor' 'drops' 'drops hint' 'eighth' 'eighth F1' 'engine'\n",
      " 'exits' 'exits F1' 'eyes' 'eyes record' 'hint' 'hint on' 'leaving'\n",
      " 'leaving F1' 'on' 'on F1' 'partner' 'partner Red' 'record'\n",
      " 'record eighth' 'sponsor' 'title']\n",
      "Number of features: 40\n",
      "{'Red': 15, 'Bull': 2, 'drops': 19, 'hint': 28, 'on': 32, 'F1': 4, 'engine': 23, 'Red Bull': 16, 'Bull drops': 3, 'drops hint': 20, 'hint on': 29, 'on F1': 33, 'F1 engine': 5, 'Honda': 11, 'exits': 24, 'leaving': 30, 'partner': 34, 'Honda exits': 12, 'exits F1': 25, 'F1 leaving': 6, 'leaving F1': 31, 'F1 partner': 7, 'partner Red': 35, 'Hamilton': 9, 'eyes': 26, 'record': 36, 'eighth': 21, 'title': 39, 'Hamilton eyes': 10, 'eyes record': 27, 'record eighth': 37, 'eighth F1': 22, 'F1 title': 8, 'Aston': 0, 'Martin': 13, 'announces': 17, 'sponsor': 38, 'Aston Martin': 1, 'Martin announces': 14, 'announces sponsor': 18}\n"
     ]
    }
   ],
   "source": [
    "#uni-gram and bi-gram\n",
    "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(1,2))\n",
    "bigrams = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(\"Number of features: {}\".format(len(vectorizer.get_feature_names_out())))\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aston Martin' 'Bull drops' 'F1 engine' 'F1 leaving' 'F1 partner'\n",
      " 'F1 title' 'Hamilton eyes' 'Honda exits' 'Martin announces' 'Red Bull'\n",
      " 'announces sponsor' 'drops hint' 'eighth F1' 'exits F1' 'eyes record'\n",
      " 'hint on' 'leaving F1' 'on F1' 'partner Red' 'record eighth']\n",
      "{'Red Bull': 9, 'Bull drops': 1, 'drops hint': 11, 'hint on': 15, 'on F1': 17, 'F1 engine': 2, 'Honda exits': 7, 'exits F1': 13, 'F1 leaving': 3, 'leaving F1': 16, 'F1 partner': 4, 'partner Red': 18, 'Hamilton eyes': 6, 'eyes record': 14, 'record eighth': 19, 'eighth F1': 12, 'F1 title': 5, 'Aston Martin': 0, 'Martin announces': 8, 'announces sponsor': 10}\n"
     ]
    }
   ],
   "source": [
    "#bi-gram only\n",
    "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(2,2))\n",
    "bigrams = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "  \"Students use their GPS-enabled cellphones to take birdview photographs of a land in order to find specific danger points such as rubbish heaps.\",\n",
    "  \"Teenagers are enthusiastic about taking aerial photograph in order to study their neighbourhood.\",\n",
    "  \"Aerial photography is a great way to identify terrestrial features that aren’t visible from the ground level, such as lake contours or river paths.\",\n",
    "  \"During the early days of digital SLRs, Canon was pretty much the undisputed leader in CMOS image sensor technology.\",\n",
    "  \"Syrian President Bashar al-Assad tells the US it will 'pay the price' if it strikes against Syria.\"\n",
    "]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "  return [t.text for t in nlp(doc) if not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Syrian', 'President', 'Bashar', 'al', 'Assad', 'tells', 'the', 'US', 'it', 'will', 'pay', 'the', 'price', 'if', 'it', 'strikes', 'against', 'Syria']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(corpus[4])\n",
    "print(spacy_tokenizer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [\"Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\"]\n",
    "new_bow = vectorizer.transform(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students use their GPS-enabled cellphones to take birdview photographs of a land in order to find specific danger points such as rubbish heaps.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.6956521739130435\n",
      "\n",
      "Teenagers are enthusiastic about taking aerial photograph in order to study their neighbourhood.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.4048204523763681\n",
      "\n",
      "Aerial photography is a great way to identify terrestrial features that aren’t visible from the ground level, such as lake contours or river paths.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.2919201796799047\n",
      "\n",
      "During the early days of digital SLRs, Canon was pretty much the undisputed leader in CMOS image sensor technology.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.19658927487319622\n",
      "\n",
      "Syrian President Bashar al-Assad tells the US it will 'pay the price' if it strikes against Syria.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.052128603514268734\n"
     ]
    }
   ],
   "source": [
    "doc1_vs_sentence = 1 - spatial.distance.cosine(bow[0].toarray(), new_bow[0].toarray())\n",
    "doc2_vs_sentence = 1 - spatial.distance.cosine(bow[1].toarray(), new_bow[0].toarray())\n",
    "doc3_vs_sentence = 1 - spatial.distance.cosine(bow[2].toarray(), new_bow[0].toarray())\n",
    "doc4_vs_sentence = 1 - spatial.distance.cosine(bow[3].toarray(), new_bow[0].toarray())\n",
    "doc5_vs_sentence = 1 - spatial.distance.cosine(bow[4].toarray(), new_bow[0].toarray())\n",
    "print(corpus[0])\n",
    "print(s[0])\n",
    "print(doc1_vs_sentence)\n",
    "print()\n",
    "print(corpus[1])\n",
    "print(s[0])\n",
    "print(doc2_vs_sentence)\n",
    "print()\n",
    "print(corpus[2])\n",
    "print(s[0])\n",
    "print(doc3_vs_sentence)\n",
    "print()\n",
    "print(corpus[3])\n",
    "print(s[0])\n",
    "print(doc4_vs_sentence)\n",
    "print()\n",
    "print(corpus[4])\n",
    "print(s[0])\n",
    "print(doc5_vs_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students use their GPS-enabled cellphones to take birdview photographs of a land in order to find specific danger points such as rubbish heaps.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.7060180864974626\n",
      "\n",
      "Teenagers are enthusiastic about taking aerial photograph in order to study their neighbourhood.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.4717281765248632\n",
      "\n",
      "Aerial photography is a great way to identify terrestrial features that aren’t visible from the ground level, such as lake contours or river paths.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.3846153846153846\n",
      "\n",
      "During the early days of digital SLRs, Canon was pretty much the undisputed leader in CMOS image sensor technology.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.3069703067574602\n",
      "\n",
      "Syrian President Bashar al-Assad tells the US it will 'pay the price' if it strikes against Syria.\n",
      "Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\n",
      "0.1349763811997543\n"
     ]
    }
   ],
   "source": [
    "def spacy_tokenizer(doc):\n",
    "  return [t.lemma_ for t in nlp(doc) if not (t.is_punct and t.is_stop)]\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True)\n",
    "bow = vectorizer.fit_transform(corpus)\n",
    "s = [\"Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\"]\n",
    "new_bow = vectorizer.transform(s)\n",
    "doc1_vs_sentence = 1 - spatial.distance.cosine(bow[0].toarray(), new_bow[0].toarray())\n",
    "doc2_vs_sentence = 1 - spatial.distance.cosine(bow[1].toarray(), new_bow[0].toarray())\n",
    "doc3_vs_sentence = 1 - spatial.distance.cosine(bow[2].toarray(), new_bow[0].toarray())\n",
    "doc4_vs_sentence = 1 - spatial.distance.cosine(bow[3].toarray(), new_bow[0].toarray())\n",
    "doc5_vs_sentence = 1 - spatial.distance.cosine(bow[4].toarray(), new_bow[0].toarray())\n",
    "print(corpus[0])\n",
    "print(s[0])\n",
    "print(doc1_vs_sentence)\n",
    "print()\n",
    "print(corpus[1])\n",
    "print(s[0])\n",
    "print(doc2_vs_sentence)\n",
    "print()\n",
    "print(corpus[2])\n",
    "print(s[0])\n",
    "print(doc3_vs_sentence)\n",
    "print()\n",
    "print(corpus[3])\n",
    "print(s[0])\n",
    "print(doc4_vs_sentence)\n",
    "print()\n",
    "print(corpus[4])\n",
    "print(s[0])\n",
    "print(doc5_vs_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = fetch_20newsgroups(categories=['sci.space'],\n",
    "                            remove=('header','footers','quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: henry@zoo.toronto.edu (Henry Spencer)\\nSubject: Re: japanese moon landing?\\nOrganization: U of Toronto Zoology\\nLines: 21\\n\\n\\nAny lunar satellite needs fuel to do regular orbit corrections, and when\\nits fuel runs out it will crash within months.  The orbits of the Apollo\\nmotherships changed noticeably during lunar missions lasting only a few\\ndays.  It is *possible* that there are stable orbits here and there --\\nthe Moon's gravitational field is poorly mapped -- but we know of none.\\n\\nPerturbations from Sun and Earth are relatively minor issues at low\\naltitudes.  The big problem is that the Moon's own gravitational field\\nis quite lumpy due to the irregular distribution of mass within the Moon.\",\n",
       " 'From: henry@zoo.toronto.edu (Henry Spencer)\\nSubject: Re: Space Station Redesign, JSC Alternative #4\\nOrganization: U of Toronto Zoology\\nLines: 10\\n\\n\\nGlad to see Griffin is spending his time on engineering rather than on\\nritual purification of the language.  Pity he got stuck with the turkey\\nrather than one of the sensible options.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "unwanted_pipes = ['ner', 'parser'] # we don't need ner and parser for this example\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "    with nlp.disable_pipes(*unwanted_pipes):\n",
    "        return [t.lemma_ for t in nlp(doc) if \\\n",
    "                not t.is_punct and \\\n",
    "                not t.is_space and \\\n",
    "                t.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.1 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
    "features = vectorizer.fit_transform(corpus.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9776\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 9776)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5245)\t0.10083250649270274\n",
      "  (0, 2423)\t0.05760094669728994\n",
      "  (0, 4472)\t0.1478972728003204\n",
      "  (0, 2536)\t0.10478449464464447\n",
      "  (0, 5090)\t0.1649813701620663\n",
      "  (0, 6950)\t0.09588654725767391\n",
      "  (0, 6209)\t0.09823567084500094\n",
      "  (0, 6759)\t0.08156582092411671\n",
      "  (0, 917)\t0.08420911679771867\n",
      "  (0, 323)\t0.10702668902936702\n",
      "  (0, 5067)\t0.0795608833533368\n",
      "  (0, 642)\t0.047502285137254206\n",
      "  (0, 4502)\t0.09907124722154151\n",
      "  (0, 5467)\t0.12791016016973922\n",
      "  (0, 7159)\t0.12081961912328393\n",
      "  (0, 2573)\t0.07115801716796445\n",
      "  (0, 8395)\t0.0887960062112186\n",
      "  (0, 6414)\t0.1341043427064035\n",
      "  (0, 5868)\t0.10478449464464447\n",
      "  (0, 4739)\t0.061347711827251336\n",
      "  (0, 9481)\t0.05873248964938554\n",
      "  (0, 1179)\t0.04729340979781867\n",
      "  (0, 5203)\t0.11884679509781822\n",
      "  (0, 6593)\t0.1478972728003204\n",
      "  (0, 3160)\t0.19177309451534783\n",
      "  :\t:\n",
      "  (0, 379)\t0.10189617730449169\n",
      "  (0, 1904)\t0.13081317543857449\n",
      "  (0, 6108)\t0.19282118869189258\n",
      "  (0, 7135)\t0.13081317543857449\n",
      "  (0, 2444)\t0.041897775284087835\n",
      "  (0, 8792)\t0.06000438474467328\n",
      "  (0, 3400)\t0.19177309451534783\n",
      "  (0, 5751)\t0.07171190884947269\n",
      "  (0, 7544)\t0.08467860037432642\n",
      "  (0, 5092)\t0.16397429971959124\n",
      "  (0, 435)\t0.068315934297386\n",
      "  (0, 4984)\t0.024688671014260876\n",
      "  (0, 9767)\t0.09443629706637464\n",
      "  (0, 8831)\t0.09240936293675692\n",
      "  (0, 6013)\t0.11676276204305176\n",
      "  (0, 9017)\t0.09114512979854562\n",
      "  (0, 6123)\t0.02562046090478795\n",
      "  (0, 4799)\t0.09664498071508269\n",
      "  (0, 5581)\t0.2772476557954008\n",
      "  (0, 4539)\t0.10822922716029153\n",
      "  (0, 7016)\t0.032840837945295416\n",
      "  (0, 8333)\t0.024647142541855033\n",
      "  (0, 8091)\t0.09053652745629993\n",
      "  (0, 3900)\t0.08614321788899483\n",
      "  (0, 3387)\t0.04929428508371007\n"
     ]
    }
   ],
   "source": [
    "print(features[0]) #this will show what the encoding looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query the data\n",
    "query = ['lunar orbit']\n",
    "query_tfidf = vectorizer.transform(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top_k(arr, k):\n",
    "    kth_largest = (k+1) * -1\n",
    "    return np.argsort(arr)[:kth_largest:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249 108   0 312 509]\n",
      "[0.44656382 0.38482292 0.24800997 0.24041302 0.20820115]\n"
     ]
    }
   ],
   "source": [
    "top_related_indices = top_k(cosine_similarities, 5)\n",
    "print(top_related_indices)\n",
    "print(cosine_similarities[top_related_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: henry@zoo.toronto.edu (Henry Spencer)\n",
      "Subject: Re: japanese moon landing?\n",
      "Organization: U of Toronto Zoology\n",
      "Lines: 22\n",
      "\n",
      "\n",
      "Actually, Hiten wasn't originally intended to go into lunar orbit at all,\n",
      "so it indeed didn't have much fuel on hand.  The lunar-orbit mission was\n",
      "an afterthought, after Hagoromo (a tiny subsatellite deployed by Hiten\n",
      "during a lunar flyby) had a transmitter failure and its proper insertion\n",
      "into lunar orbit couldn't be positively confirmed.\n",
      "\n",
      "It should be noted that the technique does have disadvantages.  It takes\n",
      "a long time, and you end up with a relatively inconvenient lunar orbit.\n",
      "If you want something useful like a low circular polar orbit, you do have\n",
      "to plan to expend a certain amount of fuel, although it is reduced from\n",
      "what you'd need for the brute-force approach.\n"
     ]
    }
   ],
   "source": [
    "print(corpus.data[top_related_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: henry@zoo.toronto.edu (Henry Spencer)\n",
      "Subject: Re: japanese moon landing?\n",
      "Organization: U of Toronto Zoology\n",
      "Lines: 14\n",
      "\n",
      "\n",
      "Their Hiten engineering-test mission spent a while in a highly eccentric\n",
      "Earth orbit doing lunar flybys, and then was inserted into lunar orbit\n",
      "using some very tricky gravity-assist-like maneuvering.  This meant that\n",
      "it would crash on the Moon eventually, since there is no such thing as\n",
      "a stable lunar orbit (as far as anyone knows), and I believe I recall\n",
      "hearing recently that it was about to happen.\n"
     ]
    }
   ],
   "source": [
    "print(corpus.data[top_related_indices[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[378 248 138 539  61]\n",
      "[0.36921296 0.3255952  0.29483236 0.2614343  0.25347882]\n"
     ]
    }
   ],
   "source": [
    "query = ['satellite']\n",
    "query_tfidf = vectorizer.transform(query)\n",
    "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()\n",
    "top_related_indices = top_k(cosine_similarities, 5)\n",
    "print(top_related_indices)\n",
    "print(cosine_similarities[top_related_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: jim@inqmind.bison.mb.ca (jim jaworski)\n",
      "Subject: Re: How many read sci.space?\n",
      "Organization: The Inquiring Mind BBS  1 204 488-1607\n",
      "Lines: 36\n",
      "\n",
      "\n",
      "\n",
      "As an Amateur Radio operator (VHF 2metres) I like to keep up with what is \n",
      "going up (and for that matter what is coming down too).\n",
      " \n",
      "In about 30 days I have learned ALOT about satellites current, future and \n",
      "past all the way back to Vanguard series and up to Astro D observatory \n",
      "(space).  I borrowed a book from the library called Weater Satellites (I \n",
      "think, it has a photo of the earth with a TIROS type satellite on it.)\n",
      " \n",
      "I would like to build a model or have a large color poster of one of the \n",
      "TIROS satellites I think there are places in the USA that sell them.\n",
      "ITOS is my favorite looking satellite, followed by AmSat-OSCAR 13 \n",
      "(AO-13).\n",
      " \n",
      "TTYL\n",
      "73\n",
      "Jim\n"
     ]
    }
   ],
   "source": [
    "print(corpus.data[top_related_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
