{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6C1kx4nFwB-B"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from nltk.corpus import treebank, brown, conll2000\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('brown')\n",
        "nltk.download('conll2000')\n",
        "nltk.download('universal_tagset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT2L_h_CwF8J",
        "outputId": "f49992c7-805e-4538-bb2e-0a3a1795db46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PoS tagger with Bidirectional LSTM"
      ],
      "metadata": {
        "id": "ySDHU0WLWY5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using the universal tagset so that different corpora will have the same PoS label"
      ],
      "metadata": {
        "id": "W-P40KgDWfls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences = treebank.tagged_sents(tagset='universal') +\\\n",
        "                    brown.tagged_sents(tagset='universal') +\\\n",
        "                    conll2000.tagged_sents(tagset='universal')\n",
        "\n",
        "print(tagged_sentences[0])\n",
        "print(f\"Dataset size: {len(tagged_sentences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNzCZQc3wJTo",
        "outputId": "e44f1bfd-8dec-4452-bd64-d57bb3e454c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
            "Dataset size: 72202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, sentence_tags = [], []\n",
        "\n",
        "for s in tagged_sentences:\n",
        "    sentence, tags = zip(*s)\n",
        "    sentences.append(list(sentence))\n",
        "    sentence_tags.append(list(tags))"
      ],
      "metadata": {
        "id": "5DEdsaTdwLn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n",
        "print(sentence_tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7it1SppwN2I",
        "outputId": "877aacc2-4d56-429f-b5aa-2cd337a45d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentences), len(sentence_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpfzcv06wRyx",
        "outputId": "4cf6ecef-58f2-4fdc-9d8b-f5443b25a6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72202 72202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.75\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, sentence_tags,\n",
        "                                                    test_size = 1 - train_ratio,\n",
        "                                                    random_state=1)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
        "                                                test_size=test_ratio/(test_ratio + validation_ratio),\n",
        "                                                random_state=1)"
      ],
      "metadata": {
        "id": "bbL47b7PwUY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))\n",
        "print(len(X_test), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynWpooR1wXzt",
        "outputId": "79be7b95-a2d6-4b74-b300-6036b75591ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54151 54151\n",
            "10830 10830\n",
            "7221 7221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokenizer = keras.preprocessing.text.Tokenizer(oov_token = \"<OOV>\")"
      ],
      "metadata": {
        "id": "HHHP9i4IwZgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "0f78PCI9wcLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary size: {len(sentence_tokenizer.word_index)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CamnHgn3wgwC",
        "outputId": "a5201d41-1bb3-4040-ec6d-b7a37755957a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 52041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We also have to create a second tokenizer to tokenize our labels\n",
        "tag_tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(y_train)"
      ],
      "metadata": {
        "id": "v6yk_XgXwh9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of PoS tags: {len(tag_tokenizer.word_index)}\\n\")\n",
        "tag_tokenizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqF-4cqzwjmS",
        "outputId": "d5bc6059-1bbb-4dc4-e47c-c5730997d26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PoS tags: 12\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_words': None,\n",
              " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
              " 'lower': True,\n",
              " 'split': ' ',\n",
              " 'char_level': False,\n",
              " 'oov_token': None,\n",
              " 'document_count': 54151,\n",
              " 'word_counts': '{\"det\": 126968, \"verb\": 174593, \"adj\": 80523, \"adp\": 136453, \"noun\": 286676, \"adv\": 51205, \".\": 142935, \"pron\": 44684, \"conj\": 35060, \"num\": 21461, \"prt\": 31229, \"x\": 6090}',\n",
              " 'word_docs': '{\"adv\": 29531, \"adp\": 43855, \"det\": 44747, \"verb\": 50837, \".\": 53332, \"adj\": 36344, \"noun\": 51171, \"conj\": 24383, \"num\": 11964, \"pron\": 26965, \"prt\": 21777, \"x\": 2682}',\n",
              " 'index_docs': '{\"7\": 29531, \"4\": 43855, \"5\": 44747, \"2\": 50837, \"3\": 53332, \"6\": 36344, \"1\": 51171, \"9\": 24383, \"11\": 11964, \"8\": 26965, \"10\": 21777, \"12\": 2682}',\n",
              " 'index_word': '{\"1\": \"noun\", \"2\": \"verb\", \"3\": \".\", \"4\": \"adp\", \"5\": \"det\", \"6\": \"adj\", \"7\": \"adv\", \"8\": \"pron\", \"9\": \"conj\", \"10\": \"prt\", \"11\": \"num\", \"12\": \"x\"}',\n",
              " 'word_index': '{\"noun\": 1, \"verb\": 2, \".\": 3, \"adp\": 4, \"det\": 5, \"adj\": 6, \"adv\": 7, \"pron\": 8, \"conj\": 9, \"prt\": 10, \"num\": 11, \"x\": 12}'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNOYXwWhwlQZ",
        "outputId": "b3eed225-9708-4d67-e955-e29fed6dfe40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'noun': 1,\n",
              " 'verb': 2,\n",
              " '.': 3,\n",
              " 'adp': 4,\n",
              " 'det': 5,\n",
              " 'adj': 6,\n",
              " 'adv': 7,\n",
              " 'pron': 8,\n",
              " 'conj': 9,\n",
              " 'prt': 10,\n",
              " 'num': 11,\n",
              " 'x': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seqs = sentence_tokenizer.texts_to_sequences(X_train)"
      ],
      "metadata": {
        "id": "qDXsGBwmwnfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_seqs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdDiM6gAwqE-",
        "outputId": "9f71a68a-e5e6-4488-f751-d22e8a4291e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27, 86, 21, 479, 7, 2, 920, 10903, 20547, 3327, 5644, 337, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original: {X_train[0]}\")\n",
        "print(f\"Reconstructed: {sentence_tokenizer.sequences_to_texts([X_train_seqs[0]])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIiUCxsGwrsJ",
        "outputId": "abe97109-ac96-400a-f78a-1b6a59ba7cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: ['This', 'may', 'be', 'due', 'to', 'the', 'heavy', 'interlobular', 'connective', 'tissue', 'barriers', 'present', '.']\n",
            "Reconstructed: ['this may be due to the heavy interlobular connective tissue barriers present .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_seqs = tag_tokenizer.texts_to_sequences(y_train)"
      ],
      "metadata": {
        "id": "KXeb08vBwtaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original: {y_train[0]}\")\n",
        "print(f\"Reconstructed: {tag_tokenizer.sequences_to_texts([y_train_seqs[0]])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQZdBjgwuwO",
        "outputId": "5b5821d7-d5f3-401e-c1d5-2bb90ba18de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: ['DET', 'VERB', 'VERB', 'ADJ', 'ADP', 'DET', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'NOUN', 'ADV', '.']\n",
            "Reconstructed: ['det verb verb adj adp det adj adj adj noun noun adv .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_seqs = sentence_tokenizer.texts_to_sequences(X_val)\n",
        "y_val_seqs = tag_tokenizer.texts_to_sequences(y_val)"
      ],
      "metadata": {
        "id": "Mv1xnYe2wvvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = len(max(X_train_seqs, key=len))\n",
        "print(f\"Length of longest input sequence: {MAX_LENGTH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfe3k94awxdD",
        "outputId": "d2a9f799-41f5-4604-c3c0-6898178de32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of longest input sequence: 161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded = keras.preprocessing.sequence.pad_sequences(X_train_seqs, padding=\"post\", maxlen=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "DuWZnMJmwyvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_padded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31cFFoKlw0Gu",
        "outputId": "6310e24a-aab3-40cd-ba4c-13bdfce248bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   27    86    21   479     7     2   920 10903 20547  3327  5644   337\n",
            "     4     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_padded = keras.preprocessing.sequence.pad_sequences(y_train_seqs, padding=\"post\", maxlen=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "gg-QUYdJw1ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_padded = keras.preprocessing.sequence.pad_sequences(X_val_seqs, padding=\"post\", maxlen=MAX_LENGTH)\n",
        "y_val_padded = keras.preprocessing.sequence.pad_sequences(y_val_seqs, padding=\"post\", maxlen=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "CCCn0HuEw3gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_categoricals = keras.utils.to_categorical(y_train_padded)"
      ],
      "metadata": {
        "id": "QUptvyDfw4ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_categoricals[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sav936tpw5iH",
        "outputId": "5643d799-3bfd-4d46-840c-d82c224163f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_categoricals[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ga95g2rw6g8",
        "outputId": "7451347f-9f64-4d56-ec5a-c8855339f436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.argmax(y_train_categoricals[0][0])\n",
        "print(f\"index: {idx}\")\n",
        "\n",
        "print(f\"Tag: {tag_tokenizer.index_word[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIEFO0BSw8RZ",
        "outputId": "4fbc6947-f807-4cd9-d77a-36b7d653fabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index: 5\n",
            "Tag: det\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_categoricals = keras.utils.to_categorical(y_val_padded)"
      ],
      "metadata": {
        "id": "PkqR69gdw9TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(sentence_tokenizer.word_index) + 1\n",
        "embedding_dim = 128\n",
        "\n",
        "num_classes = len(tag_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "TvXHr3dUw-5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(0)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=num_tokens,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=MAX_LENGTH,\n",
        "                            mask_zero=True))\n",
        "\n",
        "model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=True,\n",
        "                                            kernel_initializer=tf.keras.initializers.random_normal(seed=1))))\n",
        "\n",
        "model.add(layers.Dense(num_classes, activation='softmax',\n",
        "                        kernel_initializer=tf.keras.initializers.random_normal(seed=1)))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "lpFLRVxUw_2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyjQOv-SxBRG",
        "outputId": "ffedc452-1e68-4390-f83a-483f8fd73e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 161, 128)          6661376   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 161, 256)          263168    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 161, 13)           3341      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6927885 (26.43 MB)\n",
            "Trainable params: 6927885 (26.43 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
        "\n",
        "history = model.fit(X_train_padded, y_train_categoricals, epochs=20,\n",
        "                    batch_size=256, validation_data=(X_val_padded, y_val_categoricals),\n",
        "                    callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOtARGGYxj4k",
        "outputId": "05e8f7db-18c0-4fe5-86c1-a4f1ff681587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "212/212 [==============================] - 34s 112ms/step - loss: 0.9599 - accuracy: 0.7079 - val_loss: 0.1484 - val_accuracy: 0.9534\n",
            "Epoch 2/20\n",
            "212/212 [==============================] - 13s 60ms/step - loss: 0.1082 - accuracy: 0.9649 - val_loss: 0.1035 - val_accuracy: 0.9650\n",
            "Epoch 3/20\n",
            "212/212 [==============================] - 10s 45ms/step - loss: 0.0720 - accuracy: 0.9761 - val_loss: 0.0931 - val_accuracy: 0.9680\n",
            "Epoch 4/20\n",
            "212/212 [==============================] - 8s 38ms/step - loss: 0.0572 - accuracy: 0.9808 - val_loss: 0.0900 - val_accuracy: 0.9695\n",
            "Epoch 5/20\n",
            "212/212 [==============================] - 8s 37ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
            "Epoch 6/20\n",
            "212/212 [==============================] - 7s 32ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.0906 - val_accuracy: 0.9706\n",
            "Epoch 7/20\n",
            "212/212 [==============================] - 7s 33ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 0.0955 - val_accuracy: 0.9704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_seqs = sentence_tokenizer.texts_to_sequences(X_test)\n",
        "X_test_padded = keras.preprocessing.sequence.pad_sequences(X_test_seqs, padding='post', maxlen=MAX_LENGTH)\n",
        "\n",
        "y_test_seqs = tag_tokenizer.texts_to_sequences(y_test)\n",
        "y_test_padded = keras.preprocessing.sequence.pad_sequences(y_test_seqs, padding='post', maxlen=MAX_LENGTH)\n",
        "y_test_categoricals = keras.utils.to_categorical(y_test_padded)"
      ],
      "metadata": {
        "id": "fnqz22wbzS6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_padded, y_test_categoricals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5-QRlU8cbWS",
        "outputId": "c4ccb237-9fe3-46e7-eccd-ad56c4e0cf72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226/226 [==============================] - 2s 7ms/step - loss: 0.1009 - accuracy: 0.9698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10088780522346497, 0.9698078036308289]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    \"Brown refused to testify.\",\n",
        "    \"Brown sofas are on sale.\",\n",
        "]"
      ],
      "metadata": {
        "id": "VQirwvvmccqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_sentences(sentences):\n",
        "    sentences_seqs = sentence_tokenizer.texts_to_sequences(sentences)\n",
        "    sentences_padded = keras.preprocessing.sequence.pad_sequences(sentences_seqs, padding=\"post\", maxlen=MAX_LENGTH)\n",
        "\n",
        "    tag_preds = model.predict(sentences_padded)\n",
        "    sentence_tags = []\n",
        "\n",
        "    for i, preds in enumerate(tag_preds):\n",
        "\n",
        "        #Extracting tags for only non-padded tokens\n",
        "        tags_seq = [np.argmax(p) for p in preds[:len(sentences_seqs[i])]]\n",
        "\n",
        "        words = [sentence_tokenizer.index_word[w] for w in sentences_seqs[i]]\n",
        "        tags = [tag_tokenizer.index_word[t] for t in tags_seq]\n",
        "\n",
        "        sentence_tags.append(list(zip(words, tags)))\n",
        "\n",
        "    return sentence_tags"
      ],
      "metadata": {
        "id": "HCBz9L6KcnPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sample_sentences = tag_sentences(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15E84KYCdZgy",
        "outputId": "b4da05d0-b238-483f-c82c-51dcd1cbca25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged_sample_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw3_J9n1da4Y",
        "outputId": "ec4bc332-2304-4cb4-9206-e0a39e2ac2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('brown', 'noun'), ('refused', 'verb'), ('to', 'prt'), ('testify', 'verb')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged_sample_sentences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp78EYc9dcGp",
        "outputId": "5d350087-3d92-43a7-ec80-0e58119d7397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('brown', 'adj'), ('sofas', 'noun'), ('are', 'verb'), ('on', 'adp'), ('sale', 'noun')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Language modelling with Stacked LSTMs"
      ],
      "metadata": {
        "id": "_gJHHGd1d45Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "art_of_war = requests.get('https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/datasets/art_of_war.txt')\\\n",
        "                     .text\n",
        "\n",
        "art_of_war[:300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "JO5BIELHd-U7",
        "outputId": "24a4d865-0832-441f-bb91-4bcd5d6a6496"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Sun Tzŭ said: The art of war is of vital importance to the State.\\n\\n2. It is a matter of life and death, a road either to safety or to\\nruin. Hence it is a subject of inquiry which can on no account be\\nneglected.\\n\\n3. The art of war, then, is governed by five constant factors, to be\\ntaken into accou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)"
      ],
      "metadata": {
        "id": "qeBz8XvZddt0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([art_of_war])"
      ],
      "metadata": {
        "id": "qAwGlpWZJWYH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPp7dWt0JX0G",
        "outputId": "fd041b93-34c7-407e-fedf-5e57b1f0c467"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_words': None,\n",
              " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
              " 'lower': True,\n",
              " 'split': ' ',\n",
              " 'char_level': True,\n",
              " 'oov_token': None,\n",
              " 'document_count': 1,\n",
              " 'word_counts': '{\"1\": 179, \".\": 896, \" \": 9794, \"s\": 3081, \"u\": 1467, \"n\": 3565, \"t\": 4398, \"z\": 20, \"\\\\u016d\": 13, \"a\": 3475, \"i\": 3573, \"d\": 1681, \":\": 48, \"h\": 2558, \"e\": 5837, \"r\": 2776, \"o\": 3548, \"f\": 1238, \"w\": 981, \"v\": 478, \"l\": 1722, \"m\": 1201, \"p\": 769, \"c\": 1390, \"\\\\n\": 1443, \"2\": 127, \",\": 634, \"y\": 1055, \"b\": 708, \"j\": 23, \"q\": 55, \"g\": 1007, \"3\": 87, \"k\": 345, \"\\\\u2019\": 57, \"4\": 66, \"(\": 59, \")\": 59, \";\": 168, \"5\": 58, \"6\": 51, \"_\": 62, \"7\": 39, \"8\": 36, \"9\": 34, \"0\": 38, \"x\": 49, \"\\\\u2014\": 16, \"?\": 8, \"!\": 8, \"-\": 57, \"\\\\u201c\": 3, \"\\\\u201d\": 3, \"\\\\u0153\": 7, \"\\\\u00fc\": 3, \"\\\\u2018\": 1}',\n",
              " 'word_docs': '{\"e\": 1, \"d\": 1, \"x\": 1, \"\\\\u201d\": 1, \"\\\\u2018\": 1, \"v\": 1, \"7\": 1, \"y\": 1, \"8\": 1, \"t\": 1, \"l\": 1, \"u\": 1, \"\\\\n\": 1, \".\": 1, \"j\": 1, \"s\": 1, \"g\": 1, \")\": 1, \"w\": 1, \"9\": 1, \":\": 1, \"-\": 1, \"q\": 1, \"6\": 1, \"1\": 1, \"n\": 1, \"_\": 1, \"\\\\u016d\": 1, \"p\": 1, \"k\": 1, \"?\": 1, \"\\\\u2019\": 1, \"i\": 1, \"\\\\u201c\": 1, \"!\": 1, \"o\": 1, \"c\": 1, \"a\": 1, \"h\": 1, \"3\": 1, \"\\\\u2014\": 1, \"z\": 1, \"\\\\u00fc\": 1, \"f\": 1, \"(\": 1, \"m\": 1, \"4\": 1, \" \": 1, \"r\": 1, \"0\": 1, \",\": 1, \"2\": 1, \"b\": 1, \"\\\\u0153\": 1, \"5\": 1, \";\": 1}',\n",
              " 'index_docs': '{\"2\": 1, \"12\": 1, \"40\": 1, \"54\": 1, \"56\": 1, \"25\": 1, \"42\": 1, \"18\": 1, \"44\": 1, \"3\": 1, \"11\": 1, \"13\": 1, \"14\": 1, \"21\": 1, \"46\": 1, \"8\": 1, \"19\": 1, \"34\": 1, \"20\": 1, \"45\": 1, \"41\": 1, \"37\": 1, \"38\": 1, \"39\": 1, \"27\": 1, \"5\": 1, \"32\": 1, \"49\": 1, \"22\": 1, \"26\": 1, \"50\": 1, \"36\": 1, \"4\": 1, \"53\": 1, \"51\": 1, \"6\": 1, \"15\": 1, \"7\": 1, \"10\": 1, \"30\": 1, \"48\": 1, \"47\": 1, \"55\": 1, \"16\": 1, \"33\": 1, \"17\": 1, \"31\": 1, \"1\": 1, \"9\": 1, \"43\": 1, \"24\": 1, \"29\": 1, \"23\": 1, \"52\": 1, \"35\": 1, \"28\": 1}',\n",
              " 'index_word': '{\"1\": \" \", \"2\": \"e\", \"3\": \"t\", \"4\": \"i\", \"5\": \"n\", \"6\": \"o\", \"7\": \"a\", \"8\": \"s\", \"9\": \"r\", \"10\": \"h\", \"11\": \"l\", \"12\": \"d\", \"13\": \"u\", \"14\": \"\\\\n\", \"15\": \"c\", \"16\": \"f\", \"17\": \"m\", \"18\": \"y\", \"19\": \"g\", \"20\": \"w\", \"21\": \".\", \"22\": \"p\", \"23\": \"b\", \"24\": \",\", \"25\": \"v\", \"26\": \"k\", \"27\": \"1\", \"28\": \";\", \"29\": \"2\", \"30\": \"3\", \"31\": \"4\", \"32\": \"_\", \"33\": \"(\", \"34\": \")\", \"35\": \"5\", \"36\": \"\\\\u2019\", \"37\": \"-\", \"38\": \"q\", \"39\": \"6\", \"40\": \"x\", \"41\": \":\", \"42\": \"7\", \"43\": \"0\", \"44\": \"8\", \"45\": \"9\", \"46\": \"j\", \"47\": \"z\", \"48\": \"\\\\u2014\", \"49\": \"\\\\u016d\", \"50\": \"?\", \"51\": \"!\", \"52\": \"\\\\u0153\", \"53\": \"\\\\u201c\", \"54\": \"\\\\u201d\", \"55\": \"\\\\u00fc\", \"56\": \"\\\\u2018\"}',\n",
              " 'word_index': '{\" \": 1, \"e\": 2, \"t\": 3, \"i\": 4, \"n\": 5, \"o\": 6, \"a\": 7, \"s\": 8, \"r\": 9, \"h\": 10, \"l\": 11, \"d\": 12, \"u\": 13, \"\\\\n\": 14, \"c\": 15, \"f\": 16, \"m\": 17, \"y\": 18, \"g\": 19, \"w\": 20, \".\": 21, \"p\": 22, \"b\": 23, \",\": 24, \"v\": 25, \"k\": 26, \"1\": 27, \";\": 28, \"2\": 29, \"3\": 30, \"4\": 31, \"_\": 32, \"(\": 33, \")\": 34, \"5\": 35, \"\\\\u2019\": 36, \"-\": 37, \"q\": 38, \"6\": 39, \"x\": 40, \":\": 41, \"7\": 42, \"0\": 43, \"8\": 44, \"9\": 45, \"j\": 46, \"z\": 47, \"\\\\u2014\": 48, \"\\\\u016d\": 49, \"?\": 50, \"!\": 51, \"\\\\u0153\": 52, \"\\\\u201c\": 53, \"\\\\u201d\": 54, \"\\\\u00fc\": 55, \"\\\\u2018\": 56}'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tokenizer \\\"Vocabulary\\\" size: {len(tokenizer.word_index)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-0wS8s2JZi2",
        "outputId": "dffb8f8c-755f-4ec1-9cfc-df0830f3cc9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer \"Vocabulary\" size: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = tokenizer.texts_to_sequences([art_of_war])[0]"
      ],
      "metadata": {
        "id": "lTfHZQtfJcfL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Text length: {len(seq)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSibfBNPJr64",
        "outputId": "706c5909-c1b7-41da-9656-8c98001d12ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text length: 61054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check.\n",
        "tokenizer.sequences_to_texts([seq[:10]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5cBOIDKJ2gv",
        "outputId": "846ea1db-139b-45d6-85df-b6b90f54f51f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 .   s u n   t z ŭ']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be converting our dataset to tensorflow data so that we can perform operations on it in a easier manner"
      ],
      "metadata": {
        "id": "gIl09kRhKGkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slices = tf.data.Dataset.from_tensor_slices(seq)\n",
        "type(slices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "oqf-wSDdKBYt",
        "outputId": "373da80f-30a6-4902-a303-e54abfe90cbc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset</b><br/>def __init__(element, is_files=False, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py</a>A `Dataset` of slices from a dataset element.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 28);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(slices.take(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKXWvgW5KTzm",
        "outputId": "088fb6cb-74a6-4144-8e5d-98ad12389153"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=int32, numpy=27>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=21>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=8>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=13>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=5>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=3>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=47>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=49>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwzcpkhgKawX",
        "outputId": "69605ee8-02dd-4735-bd9e-2ca47cd9248c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27, 21, 1, 8, 13, 5, 1, 3, 47, 49]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to create input features and labels for that we will be using a windows approach"
      ],
      "metadata": {
        "id": "g_ePCPx1Kgd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_timesteps = 100\n",
        "# We are implementing teacher forcing and hence we are using the +1\n",
        "window_size = input_timesteps + 1\n",
        "windows = slices.window(window_size, shift=1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "DT1H4sLbKd4w"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in windows.take(3):\n",
        "  arr = list(w.as_numpy_iterator())\n",
        "  print(len(arr), arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFL_EzhxKszs",
        "outputId": "cd8b94eb-1a6e-4270-e2f6-aaa13b465b97"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 [27, 21, 1, 8, 13, 5, 1, 3, 47, 49, 1, 8, 7, 4, 12, 41, 1, 3, 10, 2, 1, 7, 9, 3, 1, 6, 16, 1, 20, 7, 9, 1, 4, 8, 1, 6, 16, 1, 25, 4, 3, 7, 11, 1, 4, 17, 22, 6, 9, 3, 7, 5, 15, 2, 1, 3, 6, 1, 3, 10, 2, 1, 8, 3, 7, 3, 2, 21, 14, 14, 29, 21, 1, 4, 3, 1, 4, 8, 1, 7, 1, 17, 7, 3, 3, 2, 9, 1, 6, 16, 1, 11, 4, 16, 2, 1, 7, 5, 12, 1, 12]\n",
            "101 [21, 1, 8, 13, 5, 1, 3, 47, 49, 1, 8, 7, 4, 12, 41, 1, 3, 10, 2, 1, 7, 9, 3, 1, 6, 16, 1, 20, 7, 9, 1, 4, 8, 1, 6, 16, 1, 25, 4, 3, 7, 11, 1, 4, 17, 22, 6, 9, 3, 7, 5, 15, 2, 1, 3, 6, 1, 3, 10, 2, 1, 8, 3, 7, 3, 2, 21, 14, 14, 29, 21, 1, 4, 3, 1, 4, 8, 1, 7, 1, 17, 7, 3, 3, 2, 9, 1, 6, 16, 1, 11, 4, 16, 2, 1, 7, 5, 12, 1, 12, 2]\n",
            "101 [1, 8, 13, 5, 1, 3, 47, 49, 1, 8, 7, 4, 12, 41, 1, 3, 10, 2, 1, 7, 9, 3, 1, 6, 16, 1, 20, 7, 9, 1, 4, 8, 1, 6, 16, 1, 25, 4, 3, 7, 11, 1, 4, 17, 22, 6, 9, 3, 7, 5, 15, 2, 1, 3, 6, 1, 3, 10, 2, 1, 8, 3, 7, 3, 2, 21, 14, 14, 29, 21, 1, 4, 3, 1, 4, 8, 1, 7, 1, 17, 7, 3, 3, 2, 9, 1, 6, 16, 1, 11, 4, 16, 2, 1, 7, 5, 12, 1, 12, 2, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(windows, '\\n')\n",
        "\n",
        "for w in windows.take(2):\n",
        "  print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrG4aE9-LUDH",
        "outputId": "f87a44e4-808a-4e31-aebe-13fcf89e2b12"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_WindowDataset element_spec=DatasetSpec(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorShape([]))> \n",
            "\n",
            "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>\n",
            "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To feed our model inputs in desirable format we are using the below code\n",
        "dataset = windows.flat_map(lambda window: window.batch(window_size))"
      ],
      "metadata": {
        "id": "rrRTOdcfLX-m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in dataset.take(2):\n",
        "  print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X72Hgc9L1KD",
        "outputId": "a1ff6f3f-a344-44e6-bce9-ac14abc11439"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[27 21  1  8 13  5  1  3 47 49  1  8  7  4 12 41  1  3 10  2  1  7  9  3\n",
            "  1  6 16  1 20  7  9  1  4  8  1  6 16  1 25  4  3  7 11  1  4 17 22  6\n",
            "  9  3  7  5 15  2  1  3  6  1  3 10  2  1  8  3  7  3  2 21 14 14 29 21\n",
            "  1  4  3  1  4  8  1  7  1 17  7  3  3  2  9  1  6 16  1 11  4 16  2  1\n",
            "  7  5 12  1 12], shape=(101,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[21  1  8 13  5  1  3 47 49  1  8  7  4 12 41  1  3 10  2  1  7  9  3  1\n",
            "  6 16  1 20  7  9  1  4  8  1  6 16  1 25  4  3  7 11  1  4 17 22  6  9\n",
            "  3  7  5 15  2  1  3  6  1  3 10  2  1  8  3  7  3  2 21 14 14 29 21  1\n",
            "  4  3  1  4  8  1  7  1 17  7  3  3  2  9  1  6 16  1 11  4 16  2  1  7\n",
            "  5 12  1 12  2], shape=(101,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "bW4JiPHYL2xP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches = dataset.shuffle(10000).batch(batch_size)"
      ],
      "metadata": {
        "id": "PrU3B9q8MBlL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in batches.take(2):\n",
        "  print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DppJNpNPMVl_",
        "outputId": "25fe1fe1-bdef-4f18-89c5-7f2313a5950b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 5 19  1 ... 48 14 14]\n",
            " [ 9  2  2 ...  7 12 25]\n",
            " [12  1  4 ...  2  1 23]\n",
            " ...\n",
            " [10  4  8 ... 10  6 13]\n",
            " [ 9  1 10 ...  5 15  2]\n",
            " [ 7  9 12 ...  4  8  1]], shape=(32, 101), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[17  7  5 ...  2  1 22]\n",
            " [ 8 10  1 ...  7 12  2]\n",
            " [16  1 20 ...  2 12 14]\n",
            " ...\n",
            " [12  1 12 ...  3  9  4]\n",
            " [15  6 17 ...  9  2  1]\n",
            " [ 5  2  1 ...  7 15 26]], shape=(32, 101), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xy_batches = batches.map(lambda batch: (batch[:, :-1], batch[:, 1:]))"
      ],
      "metadata": {
        "id": "56uvYfMdMTdF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in xy_batches.take(1):\n",
        "  print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "758Hh-kcM4F2",
        "outputId": "facbcef3-464c-46ac-bc91-547c0272dcca"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(32, 100), dtype=int32, numpy=\n",
            "array([[ 1,  3, 10, ...,  9, 19,  2],\n",
            "       [ 3,  7,  9, ...,  7,  1, 23],\n",
            "       [ 1, 23,  2, ...,  2,  7, 25],\n",
            "       ...,\n",
            "       [18, 24,  1, ..., 40, 10,  7],\n",
            "       [ 2,  8, 14, ...,  7, 15,  3],\n",
            "       [ 1, 16,  4, ..., 20,  7, 11]], dtype=int32)>, <tf.Tensor: shape=(32, 100), dtype=int32, numpy=\n",
            "array([[ 3, 10,  6, ..., 19,  2,  9],\n",
            "       [ 7,  9, 18, ...,  1, 23,  7],\n",
            "       [23,  2,  1, ...,  7, 25, 18],\n",
            "       ...,\n",
            "       [24,  1,  3, ..., 10,  7, 13],\n",
            "       [ 8, 14,  6, ..., 15,  3, 13],\n",
            "       [16,  4,  2, ...,  7, 11, 11]], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in xy_batches.take(1):\n",
        "  print(\"x1 length: \", len(b[0][0].numpy()))\n",
        "  print(\"x1: \", b[0][0].numpy())\n",
        "  print(\"\\n\")\n",
        "  print(\"y1 length: \", len(b[1][0].numpy()))\n",
        "  print(\"y1: \", b[1][0].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irv-_3gzM6O-",
        "outputId": "1ff3ae6c-bc90-4e76-e8ea-4ef2e406535b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 length:  100\n",
            "x1:  [26  1  3  6  1  4  9  9  4  3  7  3  2  1 10  4 17 21 14 22  9  2  3  2\n",
            "  5 12  1  3  6  1 23  2  1 20  2  7 26 24  1  3 10  7  3  1 10  2  1 17\n",
            "  7 18  1 19  9  6 20  1  7  9  9  6 19  7  5  3 21 14 14 29 30 21  1  4\n",
            " 16  1 10  2  1  4  8  1  3  7 26  4  5 19  1 10  4  8  1  2  7  8  2 24\n",
            "  1 19  4 25]\n",
            "\n",
            "\n",
            "y1 length:  100\n",
            "y1:  [ 1  3  6  1  4  9  9  4  3  7  3  2  1 10  4 17 21 14 22  9  2  3  2  5\n",
            " 12  1  3  6  1 23  2  1 20  2  7 26 24  1  3 10  7  3  1 10  2  1 17  7\n",
            " 18  1 19  9  6 20  1  7  9  9  6 19  7  5  3 21 14 14 29 30 21  1  4 16\n",
            "  1 10  2  1  4  8  1  3  7 26  4  5 19  1 10  4  8  1  2  7  8  2 24  1\n",
            " 19  4 25  2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(tokenizer.word_index) + 1\n",
        "\n",
        "# We are one hot encoding the inputs, but not the labels (that will be handled by the loss function)\n",
        "xy_batches = xy_batches.map(lambda inputs, labels: (tf.one_hot(inputs, depth=num_tokens), labels))"
      ],
      "metadata": {
        "id": "zaDiFFRoNE7O"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in xy_batches.take(1):\n",
        "  print(\"x1: \", b[0][0].numpy())\n",
        "  print(\"\\n\")\n",
        "  print(\"y1: \", b[1][0].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbWb7lIPNqpT",
        "outputId": "63bc61f7-985b-4cee-9599-035b272784dc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1:  [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "\n",
            "y1:  [25  4 15  3  6  9  4  6 13  8 28  1 10  2  1 20 10  6  1 26  5  6 20  8\n",
            "  1  3 10  2 17  1  5  6  3  1 20  4 11 11  1 16  7  4 11 21 14 14 27 29\n",
            " 21  1  3 10  2  9  2 16  6  9  2 24  1  4  5  1 18  6 13  9  1 12  2 11\n",
            "  4 23  2  9  7  3  4  6  5  8 24  1 20 10  2  5  1  8  2  2 26  4  5 19\n",
            "  1  3  6  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an optimization step where we fetch the data from the next batch while the current batch is being processed\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "ZwKIDANnNtCA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(layers.LSTM(128, return_sequences=True, input_shape=[None, num_tokens], recurrent_dropout=0.2))\n",
        "model.add(layers.LSTM(128, return_sequences=True, input_shape=[None, num_tokens], recurrent_dropout=0.2))\n",
        "\n",
        "model.add(layers.Dense(num_tokens, activation='softmax'))\n",
        "\n",
        "# Sparse categorical crossentropy enables us to not one hot encode the labels\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')\n"
      ],
      "metadata": {
        "id": "lR40JzumN8ja"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5b7llkVOHFm",
        "outputId": "5648edc5-ae48-4a4e-ac4a-8691b13f7f18"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 128)         95232     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 128)         131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 57)          7353      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 234169 (914.72 KB)\n",
            "Trainable params: 234169 (914.72 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"./ArtofWarLM/training1/cp.ckpt\"\n",
        "\n",
        "# We want to save our training progress after every epoch, so we are setting up model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "Hqn5jxx_OLop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(xy_batches, epochs=50, callbacks=[cp_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b83n2YOXOT3R",
        "outputId": "0f4bfecf-4ecb-4c7d-eb99-a8763f90db8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "   1905/Unknown - 986s 514ms/step - loss: 2.1409\n",
            "Epoch 1: saving model to ./ArtofWarLM/training1/cp.ckpt\n",
            "1905/1905 [==============================] - 987s 514ms/step - loss: 2.1409\n",
            "Epoch 2/50\n",
            "1905/1905 [==============================] - ETA: 0s - loss: 1.5652\n",
            "Epoch 2: saving model to ./ArtofWarLM/training1/cp.ckpt\n",
            "1905/1905 [==============================] - 1010s 529ms/step - loss: 1.5652\n",
            "Epoch 3/50\n",
            "1905/1905 [==============================] - ETA: 0s - loss: 1.2775\n",
            "Epoch 3: saving model to ./ArtofWarLM/training1/cp.ckpt\n",
            "1905/1905 [==============================] - 1013s 531ms/step - loss: 1.2775\n",
            "Epoch 4/50\n",
            "1905/1905 [==============================] - ETA: 0s - loss: 1.0686\n",
            "Epoch 4: saving model to ./ArtofWarLM/training1/cp.ckpt\n",
            "1905/1905 [==============================] - 992s 519ms/step - loss: 1.0686\n",
            "Epoch 5/50\n",
            "1905/1905 [==============================] - ETA: 0s - loss: 0.9192\n",
            "Epoch 5: saving model to ./ArtofWarLM/training1/cp.ckpt\n",
            "1905/1905 [==============================] - 989s 518ms/step - loss: 0.9192\n",
            "Epoch 6/50\n",
            "1905/1905 [==============================] - ETA: 0s - loss: 0.8126\n",
            "Epoch 6: saving model to ./ArtofWarLM/training1/cp.ckpt\n",
            "1905/1905 [==============================] - 976s 512ms/step - loss: 0.8126\n",
            "Epoch 7/50\n",
            "  38/1905 [..............................] - ETA: 16:34 - loss: 1.1019"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('art_of_war_char_level_lm')"
      ],
      "metadata": {
        "id": "gzzEF2QROaLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/futuremojo/nlp-demystified/raw/main/models/art_of_war_char_level_lm.zip\n",
        "!unzip -o art_of_war_char_level_lm.zip"
      ],
      "metadata": {
        "id": "b4Oag7whOjCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2679a1c6-fb6a-44b6-d5fa-3e2ffc31cc47"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-04 15:58:43--  https://github.com/futuremojo/nlp-demystified/raw/main/models/art_of_war_char_level_lm.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/models/art_of_war_char_level_lm.zip [following]\n",
            "--2024-06-04 15:58:43--  https://raw.githubusercontent.com/futuremojo/nlp-demystified/main/models/art_of_war_char_level_lm.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2691531 (2.6M) [application/zip]\n",
            "Saving to: ‘art_of_war_char_level_lm.zip’\n",
            "\n",
            "art_of_war_char_lev 100%[===================>]   2.57M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-06-04 15:58:44 (34.9 MB/s) - ‘art_of_war_char_level_lm.zip’ saved [2691531/2691531]\n",
            "\n",
            "Archive:  art_of_war_char_level_lm.zip\n",
            "   creating: art_of_war_char_level_lm/\n",
            "   creating: art_of_war_char_level_lm/assets/\n",
            "   creating: art_of_war_char_level_lm/variables/\n",
            "  inflating: art_of_war_char_level_lm/variables/variables.data-00000-of-00001  \n",
            "  inflating: art_of_war_char_level_lm/variables/variables.index  \n",
            "  inflating: art_of_war_char_level_lm/saved_model.pb  \n",
            "  inflating: art_of_war_char_level_lm/keras_metadata.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('art_of_war_char_level_lm')"
      ],
      "metadata": {
        "id": "vtK_zphT-OGh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, seed_text, num_chars=200, temperature=1):\n",
        "  text = seed_text\n",
        "\n",
        "  for _ in range(num_chars):\n",
        "    input = np.array(tokenizer.texts_to_sequences([text[-input_timesteps:]]))\n",
        "    input = tf.one_hot(input, num_tokens)\n",
        "\n",
        "    preds = model.predict(input)[0, -1:]\n",
        "    preds = tf.math.log(preds) / temperature\n",
        "\n",
        "    next_char = tf.random.categorical(preds, num_samples=1)\n",
        "    next_char = tokenizer.sequences_to_texts(next_char.numpy())[0]\n",
        "\n",
        "    text += next_char\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "HCJY-iy_-YIa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(generate_text(model, tokenizer, \"Banana peels on the battlefield can\", num_chars=300, temperature=0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylamld_XBwRj",
        "outputId": "8ac67113-c60f-4592-86c9-15fff3a5fa6e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 442ms/step\n",
            "1/1 [==============================] - 0s 475ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "Banana peels on the battlefield can never come again\n",
            "into being; nor can the dead ever be brought back to life.\n",
            "\n",
            "22. hence the enlightened ruler lays his plans well ahead;\n",
            "the good general cultivates his resources.\n",
            "\n",
            "17. move not unless you see an advantage; use not your troops unless\n",
            "there is something to be gained; fight not unless \n",
            "CPU times: user 42.7 s, sys: 948 ms, total: 43.7 s\n",
            "Wall time: 38.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1McsQSyiB_DB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}