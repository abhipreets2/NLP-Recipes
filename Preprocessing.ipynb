{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821da57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2a530",
   "metadata": {},
   "source": [
    "en_core_web_sm is trained on OntoNotes5 which is an annotated corpus comprising new, blogs, transcripts, etc. A statistical model was generated using these documents and this model is then used to predict things in subsequent documents \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fff2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b6a393f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12711619",
   "metadata": {},
   "source": [
    "### Basic spacy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbedd51e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHe didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt want to pay $20 for this book.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m(s)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "s = \"He didn't want to pay $20 for this book.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be7956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'did', \"n't\", 'want', 'to', 'pay', '$', '20', 'for', 'this', 'book', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(doc[0])\n",
    "print(type(doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd089e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He didn't\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "print(doc[0:3])\n",
    "print(type(doc[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a16d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 0), ('did', 1), (\"n't\", 2), ('want', 3), ('to', 4), ('pay', 5), ('$', 6), ('20', 7), ('for', 8), ('this', 9), ('book', 10), ('.', 11)]\n"
     ]
    }
   ],
   "source": [
    "print([(t.text, t.i) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b318f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He didn't want to pay $20 for this book.\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fe18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"Either the well was very deep, or she fell very slowly, for she \n",
    "had plenty of time as she went down to look about her and to wonder what \n",
    "was going to happen next. First, she tried to look down and make out what \n",
    "she was coming to, but it was too dark to see anything; then she looked at \n",
    "the sides of the well, and noticed that they were filled with cupboards and \n",
    "book-shelves; here and there she saw maps and pictures hung upon pegs.\"\"\"\n",
    "\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either the well was very deep, or she fell very slowly, for she \n",
      "had plenty of time as she went down to look about her and to wonder what \n",
      "was going to happen next.\n",
      "***************\n",
      "First, she tried to look down and make out what \n",
      "she was coming to, but it was too dark to see anything; then she looked at \n",
      "the sides of the well, and noticed that they were filled with cupboards and \n",
      "book-shelves; here and there she saw maps and pictures hung upon pegs.\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print(\"*\"*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"He didn't want to pay $20 for this book.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'did', \"n't\", 'want', 'to', 'pay', '$', '20', 'for', 'this', 'book', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37701d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, True, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print([t.is_currency for t in doc])\n",
    "print([t.is_digit for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$20\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    if t.is_currency:\n",
    "        if doc[t.i+1].is_digit:\n",
    "            print(t.text + doc[t.i+1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acaeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', \"'s\", 'go', 'to', 'N.Y.C.', 'for', 'the', 'weekend', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "s = \"Let's go to N.Y.C. for the weekend.\"\n",
    "TreebankWordTokenizer().tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bf0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "s = \"He told Dr. Lovato that he was done with the tests and would post the results shortly.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.lower_ for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[He, 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.lower_ if not t.is_sent_start else t for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'put', 'against', 'get', 'indeed', 'on', 'other', 'him', 'during', 'now', 'herein', 'thereby', 'has', 'if', 'own', 'anyway', 'herself', 'who', 'also', 'meanwhile', 'front', 'do', 'take', 'their', 'seem', 'thence', 'itself', 'elsewhere', 'the', 'most', 'six', 'least', 'latterly', \"'ll\", 'up', 'towards', 'next', 'whereas', 'just', 'throughout', 'either', 'beyond', 'over', '‘ll', 'much', '‘s', 'becomes', 'its', 'former', 'mine', 'nobody', 'alone', 'anyhow', 'nowhere', 'moreover', 'am', 'my', 'though', 'there', 'you', 'where', 'whereupon', '’ve', 'along', 'or', 'some', 'due', 'above', 'until', \"'ve\", 'doing', 'around', '‘ve', 'upon', 'nothing', 'five', 'namely', 'afterwards', 'i', 'already', 'become', 'others', 'often', 'again', 'below', 'under', 'eight', 'when', 'been', 'whom', 'sixty', 'go', 'down', 'which', 'move', 'seemed', 'forty', 'whoever', 'latter', 'twelve', 'same', 'seeming', 'from', 'than', 'well', 'while', 'almost', 'hereupon', 'toward', 'fifteen', 'call', 'enough', 'else', 'no', \"n't\", 'among', 'such', 'must', 'she', 'how', 'whereby', \"'re\", 'using', 'why', 'back', 'before', '’s', 'onto', 'but', 'can', 'whether', 'done', 'because', 'per', 'eleven', 'will', 'otherwise', 'any', 'hereafter', 'whither', 'say', 'ourselves', 'behind', 'every', 'through', 'once', 'here', 'many', 'in', 'are', 'however', 'made', 'it', 'besides', 'nevertheless', 'somehow', 'part', 'within', 'whence', 'yours', 'should', 'less', 'becoming', 'ca', 'formerly', 'anywhere', 'although', 'something', 'ten', 'since', 'then', 'could', 'into', 'became', 'himself', 'thereupon', 'keep', 'each', 'sometimes', 'amongst', 'side', 'hence', 'we', 'for', 'them', 'first', 'used', 'off', 'hundred', 'two', 'even', 'except', 'see', 'name', 'and', 'neither', 'so', 'hereby', 'anything', 'therefore', 'themselves', 'did', 'myself', 'everything', 'nine', 'beforehand', 'several', 'noone', 'mostly', 'yourselves', 'more', 'might', '‘re', 'to', 'three', \"'d\", 'your', 'therein', 'what', 'me', 'those', 'n’t', '‘d', 'being', 'twenty', \"'m\", 'another', 'wherein', 'always', 'everywhere', 'whole', 'not', 'hers', 'ours', 'never', 'whenever', 'together', 'very', 'is', 'out', '’m', 'cannot', 'our', 'were', 'whatever', 'four', 'serious', 'still', 'fifty', 'show', 'anyone', 'an', 'whose', 'please', 'a', 'full', 'none', 'nor', 'have', 'without', 'rather', 'beside', 'bottom', 'by', 'seems', 'really', '‘m', 'perhaps', 'does', 'give', 'thru', 'top', 'would', 'that', 'after', 'he', 'regarding', 'of', 'us', 'was', 'make', 'whereafter', 'with', 'thus', 'they', 'everyone', 'be', 'too', 'quite', '’d', '’re', 'via', 'somewhere', 'about', 'all', 'as', 'this', 'may', 'only', 'thereafter', 'across', 'his', 'ever', 'unless', 'last', 'yourself', 'wherever', 'between', \"'s\", 'yet', 'n‘t', 'her', 'third', 'various', 'these', 'empty', 'someone', 're', 'few', '’ll', 'one', 'amount', 'further', 'sometime', 'both', 'at', 'had'}\n",
      "326\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)\n",
    "print(len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e672dd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[told, Dr., Lovato, tests, post, results, shortly, .]\n"
     ]
    }
   ],
   "source": [
    "print([t for t in doc if not t.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c79e8a8",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c53e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'he'),\n",
       " ('told', 'tell'),\n",
       " ('Dr.', 'Dr.'),\n",
       " ('Lovato', 'Lovato'),\n",
       " ('that', 'that'),\n",
       " ('he', 'he'),\n",
       " ('was', 'be'),\n",
       " ('done', 'do'),\n",
       " ('with', 'with'),\n",
       " ('the', 'the'),\n",
       " ('tests', 'test'),\n",
       " ('and', 'and'),\n",
       " ('would', 'would'),\n",
       " ('post', 'post'),\n",
       " ('the', 'the'),\n",
       " ('results', 'result'),\n",
       " ('shortly', 'shortly'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.lemma_) for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f9856",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e67644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s = 'He told Dr. Lovato that he was done with the tests and would post the results shortly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0925f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a86fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he told dr. lovato that he was done with the tests and would post the results shortly.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71635301",
   "metadata": {},
   "source": [
    "### Advanced preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3252c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "s = \"John watched an old movie at the cinema.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45e66f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'PROPN'),\n",
       " ('watched', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('old', 'ADJ'),\n",
       " ('movie', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('cinema', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.pos_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045988f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e45fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'NNP'),\n",
       " ('watched', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('old', 'JJ'),\n",
       " ('movie', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cinema', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.tag_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d08b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, past tense'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('VBD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d544e7",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04096fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Volkswagen', 'ORG'),\n",
       " ('is', ''),\n",
       " ('developing', ''),\n",
       " ('an', ''),\n",
       " ('electric', ''),\n",
       " ('sedan', ''),\n",
       " ('which', ''),\n",
       " ('could', ''),\n",
       " ('potentially', ''),\n",
       " ('come', ''),\n",
       " ('to', ''),\n",
       " ('America', 'GPE'),\n",
       " ('next', 'DATE'),\n",
       " ('fall', 'DATE'),\n",
       " ('.', '')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Volkswagen is developing an electric sedan which could potentially come to America next fall.\"\n",
    "doc = nlp(s)\n",
    "\n",
    "[(t.text, t.ent_type_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95437794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f385d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Volkswagen', 'ORG'), ('America', 'GPE'), ('next', 'DATE'), ('fall', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "print([(t.text, t.ent_type_) for t in doc if t.ent_type !=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e4ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Volkswagen', 'ORG'), ('America', 'GPE'), ('next fall', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d282fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Volkswagen', 'ORG', 0, 10), ('America', 'GPE', 75, 82), ('next fall', 'DATE', 83, 92)]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e1bf19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Volkswagen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is developing an electric sedan which could potentially come to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    next fall\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17425feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ridley Scott\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " directed The \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Martian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = \"Ridley Scott directed The Martian.\"\n",
    "doc = nlp(s)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b8891",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fcb9ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f333b6165f5c49e2a5a0ab8fd054921c-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">enrolled</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">course</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">university.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f333b6165f5c49e2a5a0ab8fd054921c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = \"She enrolled in the course at the university.\"\n",
    "doc = nlp(s)\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fe893d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fb0ed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'nsubj'),\n",
       " ('enrolled', 'ROOT'),\n",
       " ('in', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('course', 'pobj'),\n",
       " ('at', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('university', 'pobj'),\n",
       " ('.', 'punct')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.dep_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cc90eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'nsubj', 'enrolled'),\n",
       " ('enrolled', 'ROOT', 'enrolled'),\n",
       " ('in', 'prep', 'enrolled'),\n",
       " ('the', 'det', 'course'),\n",
       " ('course', 'pobj', 'in'),\n",
       " ('at', 'prep', 'course'),\n",
       " ('the', 'det', 'university'),\n",
       " ('university', 'pobj', 'at'),\n",
       " ('.', 'punct', 'enrolled')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.dep_, t.head.text) for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d316b1",
   "metadata": {},
   "source": [
    "### Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03431ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "s = \"I want to book a hotel room.\"\n",
    "doc = nlp(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba6f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "  {'TEXT': 'book'},\n",
    "  {'POS': 'DET', 'OP': '?'},\n",
    "  {'POS': 'NOUN', 'OP': '+'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99902d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('USER_INTENT', [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e4dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['book a hotel', 'book a hotel room']\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332eb97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: I, root head: want\n",
      "phrase: a flight and hotel room, root head: book\n",
      "phrase: Berlin, root head: in\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I want to book a flight and hotel room in Berlin.\")\n",
    "for noun_phrase in doc.noun_chunks:\n",
    "  print(\"phrase: {}, root head: {}\".format(noun_phrase, noun_phrase.root.head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371ad321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yodize(s: str):\n",
    "    doc = nlp(s)\n",
    "    for t in doc:\n",
    "        if t.dep_ == \"ROOT\":\n",
    "            print(t.text)\n",
    "            seq = [doc[t.i + 1: -1].text, doc[0:t.i].text, t.text + \".\"]\n",
    "            seq[0] = seq[0].capitalize()\n",
    "            print(\" \".join(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97be0003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly\n",
      "To texas I will fly.\n"
     ]
    }
   ],
   "source": [
    "yodize(\"I will fly to Texas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d64efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"We'll be in Osaka on Feb 13th and leave on Feb 24th.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f8d1406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 13th, Feb 24th]\n"
     ]
    }
   ],
   "source": [
    "print([ent for ent in doc.ents if ent.label_ == \"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b406007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "s = \"Caesar Augustus was the founder of the Roman Principate (the first phase of the Roman Empire).\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "131827f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11f98372",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\"Caesar Augustus\", \"Roman Empire\"]\n",
    "patterns = [nlp.make_doc(text) for text in terms]\n",
    "matcher.add(\"TerminologyList\", patterns)\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b97453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (15, 17)]\n"
     ]
    }
   ],
   "source": [
    "print([(start, end) for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818c7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
